---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

üëã  Hi, I'm Qilin Wang, currently a first-year Ph.D. student supervised by [Prof. Hao Tang](https://scholar.google.com/citations?hl=zh-CN&user=9zJkeEMAAAAJ) in the School of Computer Science, Peking University. My research interests lie in **multimodal large language models (MLLMs)** and **AI-generated content (AIGC)**. Broadly, I am fascinated by how multimodal understanding and generative intelligence can be unified to create realistic, controllable digital humans and intelligent agents. My long-term goal is to leverage AI to create an entire movie, exploring how advanced generative models can drive end-to-end cinematic creativity.


<!-- # üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. --> 

# üìù Publications 

\* Equal contribution, ‚Ä† Corresponding author.

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICME 2025</div><img src='images/paper_2025_VividPose.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation](https://arxiv.org/abs/2405.18156)

**Qilin Wang\***, Zhengkai Jiang\*, Chengming Xu, Jiangning Zhang, Yabiao Wang, Xinyi Zhang, Yun Cao, Weijian Cao, Chengjie Wang, Yanwei Fu<sup>‚Ä†</sup>

Fudan University, Tencent

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SPL 2025</div><img src='images/paper_2025_DiffFAE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DiffFAE: Advancing High-fidelity One-shot Facial Appearance Editing with Space-sensitive Customization and Semantic Preservation](https://arxiv.org/abs/2403.17664)

**Qilin Wang**, Jiangning Zhang, Chengming Xu, Weijian Cao, Ying Tai, Yue Han, Yanhao Ge, Hong Gu, Chengjie Wang, Yanwei Fu<sup>‚Ä†</sup>

Fudan University, Tencent, Nanjing University, Zhejiang University, VIVO

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MM 2024</div><img src='images/paper_2024_MDT-A2G.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture Generation](https://arxiv.org/abs/2408.03312)

Xiaofeng Mao\*, Zhengkai Jiang\*, **Qilin Wang**, Chencan Fu, Jiangning Zhang, Jiafu Wu, Yabiao Wang, Chengjie Wang, Wei Li, Mingmin Chi<sup>‚Ä†</sup>

Fudan University, Tencent

</div>
</div>

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üìñ Educations
- <img src="images/pku_logo.png" alt="PKU" style="height:1.2em; vertical-align:middle;"> *2025.09 - 2029.06*, Ph.D. advised by [Prof. Hao Tang](https://scholar.google.com/citations?hl=zh-CN&user=9zJkeEMAAAAJ) in School of Computer Science, Peking University, Beijing, China. 
- <img src="images/fdu_logo.png" alt="FDU" style="height:1.2em; vertical-align:middle;"> *2022.09 - 2025.06*, M.S. advised by [Prof. Yanwei Fu](https://scholar.google.com/citations?user=Vg54TcsAAAAJ&hl=zh-CN) in School of Data Science, Fudan University, Shanghai, China.  
- <img src="images/whu_logo.png" alt="WHU" style="height:1.2em; vertical-align:middle;"> *2018.09 - 2022.06*, B.E. in School of Computer Science, Wuhan University, Wuhan, China.

# üíª Internships
<!-- - <img src="images/huawei_logo.png" alt="huawei" style="width:1.2em; height:1.2em; object-fit:contain; vertical-align:middle;"> *2025.09 - Present*, 2012 Lab, Huawei. -->
- <img src="images/ant_logo.png" alt="ant" style="width:1.2em; height:1.2em; object-fit:contain; vertical-align:middle;"> *2025.05 - 2025.08*, BaiLing LLM Team, Ant Group.
- <img src="images/tencent_logo.png" alt="tencent" style="width:1.2em; height:1.2em; object-fit:contain; vertical-align:middle;"> *2023.06 - 2024.09*, Youtu Lab, Tencent.

# üéñ Honors and Awards
- National Scholarship, Ministry of Education of China.
- Samsung Scholarship, Samsung.
- Outstanding Graduate & Zhicheng Scholarship & Graduate Academic Scholarship, Fudan University.
- Outstanding Graduate & Merit Student & Undergraduate Academic Scholarship, Wuhan University.

# üé® Miscellaneous
Outside of research, I enjoy exploring the world through **traveling** üèñÔ∏è and **photography** üì∏, capturing the beauty of different cultures and moments. I'm also passionate about **theatre** üé≠ and **films** üé¨, which inspire my creativity and narrative thinking. In my spare time, I love playing **badminton** üè∏ and **swimming** üèä to stay active and energized.